{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0fe06f96167c4fc64a78c238d993189072a4e72b444216e36203d6f96126eaf0a",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = {}\n",
    "dataset[\"d1\"] = \"Kampus STMIK AKBA berlokasi di Jalan Perintis Kemerdekaan No.75 Makassar.\"\n",
    "dataset[\"d2\"] = \"STMIK AKBA menyelenggarakan Wisuda Program Sarjana Ke-20 pada tahun ini. Sebanyak 100 mahasiswa STMIK AKBA akan mengikuti kegiatan wisuda ini.\"\n",
    "dataset[\"d3\"] = \"Dosen-dosen STMIK AKBA mengikuti kegiatan vaksinasi Covid-19 di aula LLDIKTI IX\"\n",
    "dataset[\"d4\"] = \"Walikota Makassar bertekad membawa Kota Makassar menjadi kota dunia.\"\n",
    "dataset[\"d5\"] = \"Pemerintah kota Makassar mendukung pendirian beberapa perguruan tinggi untuk memberikan layanan pendidikan tinggi kepada masyarakat luas.\"\n",
    "dataset[\"q\"] = \"stmik akba makassar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Folding\n",
    "for k in dataset.keys():\n",
    "    hasil_case_folding = dataset[k].lower()\n",
    "    dataset[k] = hasil_case_folding\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "for k in dataset.keys():\n",
    "    tokens = tokenizer.tokenize(dataset[k])\n",
    "    dataset[k] = tokens\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number Removal\n",
    "for k in dataset.keys():\n",
    "    tokens = []\n",
    "    for t in dataset[k]:\n",
    "        if t.isnumeric() == False:\n",
    "            tokens.append(t)\n",
    "    dataset[k] = tokens\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword Removal by Sastrawi\n",
    "factory = StopWordRemoverFactory()\n",
    "stopword_list = factory.get_stop_words()\n",
    "for k in dataset.keys():\n",
    "    tokens = []\n",
    "    for t in dataset[k]:\n",
    "        if t not in stopword_list:\n",
    "            tokens.append(t)\n",
    "    dataset[k] = tokens\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming by Sastrawi\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "for k in dataset.keys():\n",
    "    tokens = []\n",
    "    for t in dataset[k]:\n",
    "        tokens.append(stemmer.stem(t))\n",
    "    dataset[k] = tokens\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengembalikan Format Dataset Awal\n",
    "for k in dataset.keys():\n",
    "    dataset[k] = \" \".join(dataset[k])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frekuensi Kemunculan Kata\n",
    "tf = CountVectorizer()\n",
    "term_doc_matrix = tf.fit_transform(dataset.values())\n",
    "pd.DataFrame(term_doc_matrix.toarray(), index=dataset.keys(), columns=tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhitungan Euclidean Distance\n",
    "ed = euclidean_distances(term_doc_matrix, term_doc_matrix)\n",
    "df_ed = pd.DataFrame(ed, index=dataset.keys(), columns=dataset.keys())\n",
    "df_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengurutan Rangking Euclidean Distance\n",
    "rank_ed = {}\n",
    "for k in dataset.keys():\n",
    "  if k != \"q\":\n",
    "    rank_ed[k] = df_ed.at[k, \"q\"]\n",
    "top_rank_ed = dict(sorted(rank_ed.items(), key=operator.itemgetter(1)))\n",
    "pd.DataFrame(top_rank_ed.values(), index=top_rank_ed.keys(), columns=[\"Euclidean Distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembobotan TF.IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "inverted_index = tfidf.fit_transform(dataset.values())\n",
    "pd.DataFrame(inverted_index.toarray(), index=dataset.keys(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhitungan Cosine Similarity\n",
    "cs = cosine_similarity(inverted_index, inverted_index)\n",
    "df_cs = pd.DataFrame(cs, index=dataset.keys(), columns=dataset.keys())\n",
    "df_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengurutan Rangking Cosine Similarity\n",
    "rank_cs = {}\n",
    "for k in dataset.keys():\n",
    "  if k != \"q\":\n",
    "    rank_cs[k] = df_cs.at[k, \"q\"]\n",
    "top_rank_cs = dict(sorted(rank_cs.items(), key=operator.itemgetter(1), reverse=True))\n",
    "pd.DataFrame(top_rank_cs.values(), index=top_rank_cs.keys(), columns=[\"Cosine Similarity\"])"
   ]
  }
 ]
}